{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification Models",
   "id": "ec53bca13b2fbc04"
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
   ],
   "id": "d6956db4a43fb913",
   "outputs": [],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "id": "954a83ba055232b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "\n",
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "outputs": [],
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Logit\n",
    "\n",
    "1958년 영국의 통계학자 Cox가 제안한 확률 모형으로써, 독립변수의 선형 결합을 이용하여 사건의 **발생 가능성**을 예측하는 데 사용되는 통계 기법이다. 독립 변수의 선형 결합으로 종속변수를 설명하는 관점에서는 선형 회귀 분석과 유사하지만, 종속변수가 범주형 데이터를 대상으로 한다는 점에서 분류 모형이라고 할 수 있다\n",
    "\n",
    "Logit Model은 종속변수 $Y_i$가 1의 값을 갖는 확률 $p_i$를 아래와 같이 가정한다\n",
    "\n",
    "$$p_i = E(Y_i) = \\frac{1}{1+e^{-\\mathbf{\\beta X_i}}}$$\n",
    "\n",
    "이진 분류 모형의 경우 아래와 같이 분류를 생각해볼 수 있다\n",
    "\n",
    "$$p(Y_i = 1) = p_i = \\frac{1}{1+e^{-\\mathbf{\\beta X_i}}} = \\frac{e^{\\mathbf{\\beta X_i}}}{1+e^{\\mathbf{\\beta X_i}}$$\n",
    "\n",
    "$$p(Y_i = 0) = 1 - p_i = \\frac{1e^{-\\mathbf{\\beta X_i}}}{1+e^{-\\mathbf{\\beta X_i}}} = \\frac{1}{1+e^{\\mathbf{\\beta X_i}}$$\n",
    "\n",
    "추정된 $\\hat{p_i}$는 각각 1인 확률과 0인 확률을 추정한다. 여기서 추정된 확률이 0.5보다 크면 1을, 0.5보다 작으면 0으로 처리하는 분류 모형을 고려할 수 있다\n",
    "\n",
    "odds ratio는 어떤 사건이 일어날 확률을 사건이 일어나지 않을 확률로 나눈 것으로, 아래와 같이 나타낼 수 있다\n",
    "\n",
    "$$\\mathrm{odds} = \\frac{p_i}{1-p_i} = e^{\\mathbf{\\beta X_i}}$$\n",
    "\n",
    "odds ratio는 상대위험도의 척도로써 다양한 곳에서 사용되지 알아두면 좋다\n"
   ],
   "id": "ea05b97b8a8df496"
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "id": "729cf0d8792e73a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
     ]
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": "print(logit_model.summary())",
   "id": "ae6cd7c763b9f1db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Logit Regression Results                               \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
     ]
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
   ],
   "id": "142c846eb072c435",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (3, 3))\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cbar = False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "id": "6d19cd65d31b15b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ],
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Model이 얼마나 잘 분류했는지를 보는 과정 중 가장 유명한 것은 위와같이 **혼동 행렬(Confusion Matrix)** 를 보는 것이다. 혼동 행렬은 아래와 같이 나타낸다\n",
    "\n",
    "<center>\n",
    "\n",
    "|                     | Predicted positive | Predicted negative |\n",
    "|:-------------------:|:------------------:|:------------------:|\n",
    "| **Actual positive** |   True Positive    |   False negative   |\n",
    "| **Actual negative** |   False positive   |   True Negative    |\n",
    "\n",
    "</center>\n"
   ],
   "id": "e78ad5eb714f60d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8, 5))\n",
    "ax.plot([0, 1], [0, 1], 'k:')\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax.grid(False)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.yaxis.grid(True, ls = ':', alpha = 0.5) \n",
    "plt.legend()\n",
    "plt.title('ROC Curve with Logit Model')\n",
    "plt.show()"
   ],
   "id": "bcabe933dd1d6078",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Probit\n",
    "\n",
    "Probit Model은 종속변수 $Y_i$기 1의 값을 갖는 확률이 다음과 같이 계산되는 모형이다\n",
    "\n",
    "$$p_i = \\int_{- \\infty}^{\\mathbf{\\beta X_i}} \\frac{1}{\\sqrt{2\\pi}} e^{-0.5\\epsilon^2} d \\epsilon \\equiv \\Phi (\\mathbf{\\beta X_i})$$\n",
    "\n",
    "여기서 $\\Phi (\\mathbf{\\beta X_i})$는 표준정규분포의 누정분포함수를 나타내며, Logit Model과 같이 0과 1 사이의 값을 가지는 확률을 추정한다\n",
    "\n",
    "한편, 모형의 parameter는 일반적인 선형모델처럼 바로 구할 수는 없으며, Maximum Likelihood Extimation을 사용하여 구할 수 있다. \n",
    "\n",
    "Logit Model과 Probit Model 모두 고전적인 통계 모형에서 분류 모형에 해당하는 것으로, sklearn에서는 `Logistic Regression`이 같은 역할을 한다"
   ],
   "id": "6b91cde2b027a7fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(probit_model.summary())"
   ],
   "id": "7312eee615774181",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "                              Probit Regression Results                               \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
     ]
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
   ],
   "id": "c9c5b04747899074",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize = (3, 3))\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cbar = False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix', fontsize = 12, fontfamily = 'Serif')\n",
    "plt.show()"
   ],
   "id": "73c6eddc16ec9140",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ],
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8, 5))\n",
    "ax.plot([0, 1], [0, 1], 'k:')\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax.grid(False)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.yaxis.grid(True, ls = ':', alpha = 0.5) \n",
    "plt.legend()\n",
    "plt.title('ROC Curve with Probit Model')\n",
    "plt.show()"
   ],
   "id": "fd79b47171872bd1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Naive Bayes\n",
    "\n",
    "모형의 이름에서 볼 수 있듯이 굉장히 Naive한 모형이다. discrete, continuous한 feature들 모두 사용이 가능하며, sklearn에는 다음과 같은 모형이 존재한다\n",
    "\n",
    "**Discrete Naive Bayes Algorithms**\n",
    "\n",
    "- `sklearn.naive_bayes.BernoulliNB` : 이진(0 또는 1) 값을 갖는 특성에 적합하다. 텍스트 분류에서 단어의 출현 여부를 이진 특성으로 다룰 때 유용하다고 한다\n",
    "- `sklearn.naive_bayes.MultinomialNB` : 주로 텍스트 분류 작업에 사용된다. 이 모델은 특성이 다항 분포를 따른다고 가정한다\n",
    "- `sklearn.naive_bayes.ComplementNB` : 데이터의 분포가 불균형할 때 좋다\n",
    "- `sklearn.naive_bayes.CategoricalNB` : Categorical Distribution을 가정한다. 성능에 대해서는 그리 많이 알려져 있지 않다\n",
    "\n",
    "**Continuous Naive Bayes Algorithm**\n",
    "\n",
    "- `sklearn.naive_bayes.GaussianNB` : 연속적인 값에서 Naive Bayes Classification이 가능하다\n",
    "\n",
    "그 중 Gaussian Naive Bayes 모형은 feature가 연속적인 경우에 사용되며, 패턴 인식에 큰 장점을 보인다. 무엇보다도, 연산 속도가 타 분류 모형에 비해 굉장히 빠르다는 것이 큰 장점이다\n",
    "\n",
    "```\n",
    "sklearn.naive_bayes.GaussianNB(*, priors=None, var_smoothing=1e-09)\n",
    "```\n",
    "\n",
    "단 데이터의 특성이 지수 분포족에 따를 때에만 성능이 좋고, feature간에 조건부독립성이 성립하지 않는다면 분류 결과가 치우쳐질 가능성이 높다"
   ],
   "id": "b616670b8b8162de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 3.1 Bayes' Theorem\n",
    "\n",
    "나이브 베이즈 분류기는 베이즈 정리를 기반으로 동작한다. 베이즈 정리는 다음과 같이 표현된다\n",
    "\n",
    "$$P(C_k | X) = \\frac{P(X | C_k) P(C_k)}{P(X)}$$\n",
    "\n",
    "여기서\n",
    "\n",
    "- $P(C_k | X)$는 주어진 데이터 $X$가 클래스 $C_k$에 속할 조건부 확률 (Posterior)\n",
    "- $P(X | C_k)$는 클래스 $C_k$에서 데이터 $X$가 나올 조건부 확률 (Likelihood)\n",
    "- $P(C_k)$는 클래스 $C_k$에 대한 사전 확률\n",
    "- $P(X)$는 데이터 $X$의 전체 확률 (증거)\n",
    "나이브 베이즈 분류기의 목표는 사후 확률 $P(C_k | X)$를 계산하는 것이다. 사후 확률은 주어진 데이터가 특정 클래스에 속할 확률을 나타낸다."
   ],
   "id": "a7c045c9567cfdfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 3.2 Conditional Identification\n",
    "\n",
    "나이브 베이즈 분류기의 핵심 가정은 조건부 독립성이다. 즉, 모든 특성 $x_i$는 독립적으로 클래스 $C_k$에 영향을 미친다고 가정한다. 이 가정에 따르면, 데이터 $X = {x_1, x_2, \\dots, x_n}$의 각 특성 $x_i$는 서로 독립적이다. 따라서, 조건부 확률 $P(X | C_k)$는 각 특성의 조건부 확률의 곱으로 표현할 수 있다.\n",
    "\n",
    "$$P(X | C_k) = P(x_1, x_2, \\dots, x_n | C_k) = \\prod_{i=1}^{n} P(x_i | C_k)$$\n",
    "\n",
    "이 식은 데이터의 각 특성이 서로 독립적이라는 가정을 기반으로 한다. 이를 통해 계산이 단순화된다."
   ],
   "id": "93114e345bef1bc5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 3.3 Posterior Probability\n",
    "\n",
    "이제 베이즈 정리에 이 조건부 독립성 가정을 적용하여, 사후 확률 $P(C_k | X)$를 다음과 같이 다시 쓸 수 있다\n",
    "\n",
    "$$P(C_k | X) = \\frac{P(C_k) \\prod_{i=1}^{n} P(x_i | C_k)}{P(X)}$$\n",
    "\n",
    "여기서 $P(X)$는 모든 클래스에 대해 동일하므로, 이를 생략하고 사후 확률은 다음과 같이 비례식으로 표현할 수 있다\n",
    "\n",
    "$$P(C_k | X) \\propto P(C_k) \\prod_{i=1}^{n} P(x_i | C_k)$$\n",
    "\n",
    "따라서, 나이브 베이즈 분류기는 사전 확률 $P(C_k)$와 각 특성 $x_i$가 주어진 클래스 $C_k$에 속할 조건부 확률 $P(x_i | C_k)$의 곱을 계산하여, 각 클래스의 사후 확률을 구하게 된다."
   ],
   "id": "f8ecf055bd5dc1f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 3.4 Classification Criterion\n",
    "\n",
    "나이브 베이즈 분류기는 각 클래스의 사후 확률을 비교하여 가장 큰 확률을 가지는 클래스를 선택한다. 즉, 다음과 같은 방식을 따른다\n",
    "\n",
    "$$\\hat{C} = \\arg\\max_{C_k} P(C_k) \\prod_{i=1}^{n} P(x_i | C_k)$$\n",
    "\n",
    "이 식에서\n",
    "\n",
    "- $\\hat{C}$는 사후 확률이 가장 큰 클래스를 나타낸다.\n",
    "- MAP (Maximum A Posteriori) 추정 방식에 따라, 가장 큰 사후 확률을 가지는 클래스를 선택한다.\n",
    "\n",
    "나이브 베이즈의 조건부 독립성 가정은 계산을 단순화하지만, 실제 데이터에서 특성 간에 상관관계가 존재하는 경우 이 가정이 잘 맞지 않을 수 있다. 그럼에도 불구하고, 나이브 베이즈는 많은 경우에서 효율적이고 성능이 좋은 분류기로 널리 사용된다."
   ],
   "id": "63d7b8f6e100e058"
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
   ],
   "id": "5e98e1abde2b0de8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Accuracy: {accuracy}')"
   ],
   "id": "d11bfc5c72772273",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "id": "d71d5c870c016bf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize = (3, 3))\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cbar = False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "id": "8c6a508a56028e2d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ],
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8, 5))\n",
    "ax.plot([0, 1], [0, 1], 'k:')\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax.grid(False)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.yaxis.grid(True, ls = ':', alpha = 0.5) \n",
    "plt.legend()\n",
    "plt.title('ROC Curve with Naive Bayes')\n",
    "plt.show()"
   ],
   "id": "435574601a2520af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
